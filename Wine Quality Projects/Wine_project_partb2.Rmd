---
title: "Brett Karsten [part 2 part b]"
output:
  html_document:
    df_print: paged
---


```{r}
library(tidyverse)
library(stats4)
```

```{r}
red_wine = read_csv("/Users/brettkarsten/VS code/Applied Stat methods project/Wine Quality/winequality-red.csv")
```
## Question 1 Part E: e.  Can  we  use  a  normal  distribution  to  model  “density”?  If  yes,  what  are  the maximum  likelihood  estimates  of  the  mean  and  standard  deviation?  Please provide their standard errors as well.


### 1e. To find the MLEs, you may consider multiplying the data by 10. This will solve a numerical problem you may encounter. You must transform back in the end.


```{r}
density_data <- (red_wine$density)
```

```{r}
density_data
```
```{r}
sd(density_data)
```

```{r}
density_data2 <- density_data * 10 # multiply by 10 to make this easier 
```

```{r}
hist(density_data)
```

Yes, a normal distribution can be used to model the density data. We can see a normal distribution with the histogram displayed above. To use the maximum likelihood estimation, we will multiply the density data values by 10 and then divide the estimates and SE values by 10 to get the right results. The raw values are too small to use so multiplying by 10 is necessary.

```{r}
sd(density_data2)
```

```{r}
hist(density_data2)
```

As outlined in the notes...

```{r}
dnorm(density_data2[1], mean = mean(density_data2), sd = sd(density_data2))
```

```{r}
mu_density2 <- mean(density_data2)
sigma_density2 <- sd(density_data2)
```


Now lets create the MLE function 


```{r}
# define the function

minuslog.lik <- function(mu, sigma) {
  log.lik <- 0
  for(value in 1:1599) { # here is the sample size
    log.lik <- log.lik + log(dnorm(density_data2[value], mean = mu, sd = sigma))
  } 
    return(-log.lik)
}

```

now lets calculate the estimation 

```{r}
MLE_est_density <- mle(minuslog = minuslog.lik, start = list(mu = mu_density2, 
                                      sigma = sigma_density2))
summary(MLE_est_density)
```

The MLE for the density mean is 0.99675 (output divided by 10). The standard error value for mu
is 0.0000472 (output divided by 10). The MLE for the standard deviation is 0.00188 (output divided by 10) and the standard error is 0.00003297 for sd. 

## Question 2 part D: Can we use a normal distribution to model “residual sugar”? If no, what distribution do you think can approximate its empirical distribution? What parameters are needed to characterize such a distribution? what are their maximum likelihood estimates? Please provide their standard errors as well

Lets first look at the distribution 

```{r}
residual_sugar <- (red_wine$`residual sugar`)
```

```{r}
hist(residual_sugar)
```

We can see this data is heavily skewed, this is not representative of a normal distribution so we cannot use dnorm when finding the MLE for mean and sd. The above distribution would be a lognorm distribution so we will have to redefine the minus.log function to take these parameters into account. 

meanlog and sigmalog, (mean and standard deviation) are the parameters used for this MLE.

```{r}
meanlog_rs <- log(mean(residual_sugar))
sigmalog_rs <- log(sd(residual_sugar))
```


```{r}


minuslog.lik <- function(mu, sigma) {
  log.lik <- 0
  for(value in 1:1599) { # here is the sample size
    log.lik <- log.lik + log(dlnorm(x = red_wine$`residual sugar`[value], meanlog = mu, sdlog = sigma))
  } 
    return(-log.lik)
}

```


```{r, warning=FALSE}

MLE_est_rs <- mle(minuslog = minuslog.lik, start = list(mu=log(mean(red_wine$`residual sugar`)), sigma=log(sd(red_wine$`residual sugar`))))

print(summary(MLE_est_rs))

```

The MLE for the mean is 0.8502341 with a standard error of 0.008935942. The MLE for sd is 0.3573260 with a standard error of 0.006318293.

We can also run a simulation to compare the outputs. 

As outlined in the notes...

```{r}
rsugar.simulate <- rlnorm(1599, meanlog = 0.8502341, sdlog = 0.3573260)

par(mfrow = c(1, 2))
hist(rsugar.simulate, breaks = seq(from = 0, to = 15, by = 1))
hist(red_wine$`residual sugar`, breaks = seq(from = 0, to = 20, by = 1))
```


## Question 3 part D What is the maximum likelihood estimate of p and its standard error? 

Note: you need to create a new column of data for the new variable “excellent” which
has binary values (0 and 1). Its value is 1 if the wine rating >=7, and otherwise its value
is 0. Then, you can make inference about the underlying proportion parameter p using
this column of data.

p = proportions of wines with a rating >= 7


```{r}
red_wine$excellent <- as.numeric(red_wine$quality >= 7)
```

```{r}
red_wine$excellent
```

```{r}
hist(red_wine$excellent)
```

Since there are two values for this distribution, it will be a binomial distribution. We will need to redefine the likelihood function. 

```{r}

minuslog.lik <- function(p) { # p = proportion of excellent wines
  log.lik <- 0
  for (value in 1:1599) {
    log.lik <- log.lik + log(dbinom(red_wine$excellent[value], size = 1, prob = p))
  }
  return(-log.lik)
}

MLE_est_excellent <- mle(minuslog = minuslog.lik, start = list(p = mean(red_wine$excellent)))

summary(MLE_est_excellent)

```
The estimate for the proportion of wines with a rating >= 7 is p = 0.1357098. Its standard error is 0.008564278.


```{r}
excellent.simulate <- rbinom(1599, size = 1, prob = 0.1357098)

par(mfrow = c(1, 2))
hist(excellent.simulate, breaks = seq(from = 0, to = 1, by = 0.20))
hist(red_wine$excellent, breaks = seq(from = 0, to = 1, by = 0.20))
```

